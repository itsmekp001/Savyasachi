{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install gpt_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader,GPTListIndex,GPTVectorStoreIndex,LLMPredictor,PromptHelper\n",
    "from langchain import OpenAI\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"PuNgYGwwn2xL2SWvZiH7T3BlbkFJUCyemcqoK4871gWgN05V\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVectorIndex(path):\n",
    "    max_input = 4096\n",
    "    token = 256\n",
    "    chunk_size = 600\n",
    "    max_chunk_overlap = 20\n",
    "\n",
    "    prompt_helper = PromptHelper(max_input,token,max_chunk_overlap,chunk_size_limit = chunk_size)\n",
    "\n",
    "    #define LLM\n",
    "    llmpredictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-ada-001\", max_tokens=token))\n",
    "\n",
    "    #load data\n",
    "    docs = SimpleDirectoryReader(path).load_data()\n",
    "\n",
    "\n",
    "    #Create vector index \n",
    "\n",
    "    vectorIndex = GPTVectorStoreIndex(documents= docs,llm_predictor = llmpredictor,prompt_helper= prompt_helper)\n",
    "    vectorIndex.save_to_disk('vector_index.json')\n",
    "    return vectorIndex\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of documents or index_struct must be provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vectorIndex \u001b[39m=\u001b[39m createVectorIndex(\u001b[39m'\u001b[39;49m\u001b[39mdata_files\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[12], line 18\u001b[0m, in \u001b[0;36mcreateVectorIndex\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     13\u001b[0m docs \u001b[39m=\u001b[39m SimpleDirectoryReader(path)\u001b[39m.\u001b[39mload_data()\n\u001b[0;32m     16\u001b[0m \u001b[39m#Create vector index \u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m vectorIndex \u001b[39m=\u001b[39m GPTVectorStoreIndex(documents\u001b[39m=\u001b[39;49m docs,llm_predictor \u001b[39m=\u001b[39;49m llmpredictor,prompt_helper\u001b[39m=\u001b[39;49m prompt_helper)\n\u001b[0;32m     19\u001b[0m vectorIndex\u001b[39m.\u001b[39msave_to_disk(\u001b[39m'\u001b[39m\u001b[39mvector_index.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[39mreturn\u001b[39;00m vectorIndex\n",
      "File \u001b[1;32mc:\\Users\\KP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:44\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex.__init__\u001b[1;34m(self, nodes, index_struct, service_context, storage_context, use_async, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initialize params.\"\"\"\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_async \u001b[39m=\u001b[39m use_async\n\u001b[1;32m---> 44\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     45\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[0;32m     46\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[0;32m     47\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[0;32m     48\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[0;32m     49\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m     50\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\KP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\base.py:45\u001b[0m, in \u001b[0;36mBaseGPTIndex.__init__\u001b[1;34m(self, nodes, index_struct, storage_context, service_context, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initialize with parameters.\"\"\"\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m index_struct \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m nodes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOne of documents or index_struct must be provided.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[39mif\u001b[39;00m index_struct \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m nodes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOnly one of documents or index_struct can be provided.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: One of documents or index_struct must be provided."
     ]
    }
   ],
   "source": [
    "vectorIndex = createVectorIndex('data_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answerMe(vectorIndex):\n",
    "    vIndex = GPTVectorStoreIndex.load_from_disk(vectorIndex)\n",
    "    while True:\n",
    "        prompt = input('Please ask: ')\n",
    "        response = vIndex.query(prompt,response_mode=\"compact\")\n",
    "        print(f\"Response: {response} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerMe('vector_index.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
